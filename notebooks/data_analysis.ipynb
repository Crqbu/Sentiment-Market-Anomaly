{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision torchaudio\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lazy_df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mscan_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMert\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCourses\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFinancial Big Data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnasdaq_exteral_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lazy_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlazy_df\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lazy_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lazy_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mlazy_df\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mselect([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle_title\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# Select specific columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle_title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_not_null())  \u001b[38;5;66;03m# Filter null values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Filter Stock_symbol == AAPL \u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS UTC\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Convert Date to proper datetime format\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lazy_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m apple_df \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mfiltered_df\u001b[49m\u001b[38;5;241m.\u001b[39mcollect())\n\u001b[1;32m      2\u001b[0m             \u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;241m0\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock_Symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m2\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle_title\u001b[39m\u001b[38;5;124m\"\u001b[39m}, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apple_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapple_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/apple_news.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apple_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Cleaning our data\n",
    "\n",
    "Here I needed to properly clean the dataset we have before processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_Symbol</th>\n",
       "      <th>Article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-16 22:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>My 6 Largest Portfolio Holdings Heading Into 2024 -- and the Important Investing Lesson I Learned From Each One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-16 22:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Company News for Dec 19, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NVIDIA (NVDA) Up 243% YTD: Will It Carry Momentum in 2024?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Date Stock_Symbol  \\\n",
       "0           0  2023-12-16 22:00:00         AAPL   \n",
       "1           1  2023-12-16 22:00:00         AAPL   \n",
       "2           2  2023-12-16 21:00:00         AAPL   \n",
       "3           3  2023-12-16 21:00:00         AAPL   \n",
       "4           4  2023-12-16 21:00:00         AAPL   \n",
       "\n",
       "                                                                                                     Article_title  \n",
       "0  My 6 Largest Portfolio Holdings Heading Into 2024 -- and the Important Investing Lesson I Learned From Each One  \n",
       "1                                        Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet  \n",
       "2                                                                                    Company News for Dec 19, 2023  \n",
       "3                                                       NVIDIA (NVDA) Up 243% YTD: Will It Carry Momentum in 2024?  \n",
       "4     Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First choose what dataset we want to clean.\n",
    "#I want us to first work with Apple news dataset but we could work with any dataset (just replace the path)\n",
    "df_to_clean = pd.read_csv(\"../data/apple_news.csv\")\n",
    "df_to_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO :\n",
    "-Remove unnamed index column\n",
    "-Parse the Date column to datetime format.\n",
    "-Incorporate sentiment analysis with Dis roberta to generate sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop the column 'Unnamed: 0' from the DataFrame 'df_to_clean' becuase it is not needed for analysis.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_to_clean \u001b[38;5;241m=\u001b[39m \u001b[43mdf_to_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert the 'Date' column to a datetime object\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_to_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_to_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop the column 'Unnamed: 0' from the DataFrame 'df_to_clean' becuase it is not needed for analysis.\n",
    "df_to_clean = df_to_clean.drop(columns=['Unnamed: 0'])\n",
    "# Convert the 'Date' column to a datetime object\n",
    "df_to_clean['Date'] = pd.to_datetime(df_to_clean['Date'])\n",
    "#filter the DataFrame 'df_filtered' to only include rows where the 'Article_title' column contains the word 'Apple' or 'AAPL'.\n",
    "df_filtered = df_to_clean[df_to_clean['Article_title'].str.contains(r'\\b(Apple|AAPL)\\b', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_Symbol</th>\n",
       "      <th>Article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-16 22:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-16 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL Quantitative Stock Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-12-16 04:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>After Hours Most Active for Dec 18, 2023 : PACB, AAPL, VTIP, EDAP, FTNT, AMZN, HPE, SKT, VZ, MRK, BVN, PFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-12-16 04:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology Sector Update for 12/18/2023: PCT, ADBE, AAPL, EBIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>2020-03-10 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Peloton Shares Tick To Session Low As Hearing Report Apple Working On 'Guided Workout' Fitness App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>2020-03-10 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>UBS Maintains Buy on Apple, Lowers Price Target to $335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>2020-05-31 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple CEO Writes To Employees About George Floyd Death, Urges For 'Better, More Just World For Everyone'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>2020-05-28 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tredje AP-fonden Buys Microsoft Corp, Amazon.com Inc, Apple Inc, Sells iShares U.S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>2020-05-28 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>The Zacks Analyst Blog Highlights: Apple, Exxon Mobil, Cisco System and Chevron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2784 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date Stock_Symbol  \\\n",
       "1    2023-12-16 22:00:00         AAPL   \n",
       "4    2023-12-16 21:00:00         AAPL   \n",
       "6    2023-12-16 20:00:00         AAPL   \n",
       "15   2023-12-16 04:00:00         AAPL   \n",
       "16   2023-12-16 04:00:00         AAPL   \n",
       "...                  ...          ...   \n",
       "9099 2020-03-10 00:00:00         AAPL   \n",
       "9105 2020-03-10 00:00:00         AAPL   \n",
       "9115 2020-05-31 00:00:00         AAPL   \n",
       "9135 2020-05-28 00:00:00         AAPL   \n",
       "9136 2020-05-28 00:00:00         AAPL   \n",
       "\n",
       "                                                                                                     Article_title  \n",
       "1                                        Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet  \n",
       "4     Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR  \n",
       "6                                                                                 AAPL Quantitative Stock Analysis  \n",
       "15      After Hours Most Active for Dec 18, 2023 : PACB, AAPL, VTIP, EDAP, FTNT, AMZN, HPE, SKT, VZ, MRK, BVN, PFE  \n",
       "16                                                  Technology Sector Update for 12/18/2023: PCT, ADBE, AAPL, EBIX  \n",
       "...                                                                                                            ...  \n",
       "9099            Peloton Shares Tick To Session Low As Hearing Report Apple Working On 'Guided Workout' Fitness App  \n",
       "9105                                                       UBS Maintains Buy on Apple, Lowers Price Target to $335  \n",
       "9115      Apple CEO Writes To Employees About George Floyd Death, Urges For 'Better, More Just World For Everyone'  \n",
       "9135                       Tredje AP-fonden Buys Microsoft Corp, Amazon.com Inc, Apple Inc, Sells iShares U.S. ...  \n",
       "9136                               The Zacks Analyst Blog Highlights: Apple, Exxon Mobil, Cisco System and Chevron  \n",
       "\n",
       "[2784 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, save the cleaned dataset\n",
    "#If we work with another dataset, change the path\n",
    "df_filtered.to_csv(\"../data/clean/apple_news_c.csv\")\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. News-data Preprocessing\n",
    "\n",
    "#### Here we start our data processing work to convert get the sentiment\n",
    "\n",
    "Assume that the dataset of the news is a constant flow of the news, then we try to construct a stochastic process on sentiment: use distrillroberta to generate sentiment(positive, neutral, negative) of the news headline and labelled the as (1, 0, -1) scores. Noted that the news are always released in two ways: one is that the news are released at midnight(or non-trading time) in batches, the others are released during trading time without batches(a flow-released news). For batch-released news, average the sentiment score.\n",
    "\n",
    "THe formula for the stochastic process is be written as \n",
    "\n",
    "$$\n",
    "I_t^s = \\sum_{j} g(f(e_{jt}^{s})), \n",
    "g(x) = \\begin{cases} 1, x = \"Positive\"\\\\\n",
    "0, x = \"Neutral\"\\\\\n",
    "-1, x = \"Negative\"\\\\\n",
    "\\end{cases},\n",
    "\n",
    "f(x) = roBERTa(x),\n",
    "\n",
    "$$\n",
    "\n",
    "$f(x)$ is the pretrained sentiment classifier. $e_{jt}^{s}$ means the $j$-th embedding of the news headline at time $t$ for the stock $s$.\n",
    "\n",
    "**Note**: time $t$ is not the natural time for trading, but it's proxy time interval between the new release, and it differs from stock to stock. Think of it as some sort of jump process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_Symbol</th>\n",
       "      <th>Article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-16 22:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Date Stock_Symbol  \\\n",
       "0           1  2023-12-16 22:00:00         AAPL   \n",
       "1           4  2023-12-16 21:00:00         AAPL   \n",
       "\n",
       "                                                                                                  Article_title  \n",
       "0                                     Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet  \n",
       "1  Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv(\"../data/clean/apple_news_c.csv\")\n",
    "cleaned_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment classification completed and saved to processed_news_data_with_sent.csv.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch\n",
    "\"\"\"\n",
    "This script performs sentiment analysis on financial news articles using the PRE-TRAINED model we selected from Hugging Face.\n",
    "The sentiment analysis model used is 'distilroberta-finetuned-financial-news-sentiment-analysis', which is fine-tuned on the financial_phrasebank dataset.\n",
    "\n",
    "Functions:\n",
    "    classify_sentiment(article: str) -> int:\n",
    "        Classifies the sentiment of a given article as positive, negative, or neutral.\n",
    "        Returns 1 for positive sentiment, -1 for negative sentiment, and 0 for neutral sentiment.\n",
    "\n",
    "The script reads a DataFrame 'cleaned_df' containing financial news articles, applies sentiment analysis to the 'Article_title' column,\n",
    "and saves the resulting DataFrame with sentiment scores to a CSV file.\n",
    "\n",
    "Usage:\n",
    "    Ensure that the required libraries are installed and the input DataFrame 'cleaned_df' is loaded.\n",
    "    Run the script to perform sentiment analysis and save the results to a CSV file.\n",
    "\"\"\"\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# We will use distilRoberta-financial-sentiment a fine-tuned version of distilroberta-base on the financial_phrasebank dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Let's apply the discussed sentiment analysis\n",
    "def classify_sentiment(article):\n",
    "    sentiment_result = sentiment_pipeline(article)[0]\n",
    "    label = sentiment_result['label']\n",
    "    if label == \"positive\":\n",
    "        return 1\n",
    "    elif label == \"negative\":\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Now we need to merge the sentiment scores to the dataset (AND AFTER MERGE INDEX)\n",
    "cleaned_df['Sentiment'] = cleaned_df['Article_title'].apply(classify_sentiment)\n",
    "cleaned_df.to_csv(\"../data/processed/processed_news_data_with_sent.csv\", index=False)\n",
    "print(\"Sentiment classification completed and saved to processed_news_data_with_sent.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_Symbol</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-16 22:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-12-16 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Date Stock_Symbol  \\\n",
       "0           1  2023-12-16 22:00:00         AAPL   \n",
       "1           4  2023-12-16 21:00:00         AAPL   \n",
       "\n",
       "                                                                                                  Article_title  \\\n",
       "0                                     Brokers Suggest Investing in Apple (AAPL): Read This Before Placing a Bet   \n",
       "1  Pre-Market Most Active for Dec 19, 2023 : BMY, SQQQ, NIO, UBS, TQQQ, UBER, NVDA, AAPL, GOTU, CAN, TSLA, PLTR   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1          0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we merge the sentiment scores to the dataset\n",
    "merged_df = pd.read_csv(\"../data/processed/processed_news_data_with_sent.csv\")\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Price-data preprocessing\n",
    "\n",
    "#### Now that we have our data set with the sentiments, we want to link it to our stock price\n",
    "\n",
    "Discretize the tick-by-tick data to align with the news-data, by identifying the return of the price. When the batch news are released in non-trading time, assume that the traders in the market will react to the news as soon as the trading time starts, for flow-released news, assume that the market participants will react as soon as the information of the news is understood. There will be two hyperparameter: the time-lag between the new release and the market reaction, and the fixed timeframe that uses to calculate the return of the price. Set the return of the stock as positive, stable and negative under a threshold and label it as (1,0,-1). Then we construct a stochastic process for stock return.\n",
    "\n",
    "The formula for the stochastic process of the discretized return can be written as \n",
    "\n",
    "$$\n",
    "R_{t}^{s} = h(\\log \\frac{P_{t + \\delta}^{s}}{P_{t}^{s}}), \n",
    "\n",
    "h(x) = \\begin{cases}1, x > \\gamma \\\\ 0, \\|x\\| \\leq \\gamma \\\\ -1, x < -\\gamma\\end{cases},\n",
    "\n",
    "\\gamma, \\delta > 0\n",
    "$$\n",
    "\n",
    "$P_{t}^{s}$ is the price of stock $s$ at time $t$, $\\delta$ is the timeframe for the return calculation, $\\gamma$ is the threshold of classifying the return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Cleaning the price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/1981</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.155134</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.119849</td>\n",
       "      <td>21660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/1981</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.117244</td>\n",
       "      <td>35728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/1981</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.143973</td>\n",
       "      <td>0.143973</td>\n",
       "      <td>0.112032</td>\n",
       "      <td>45158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/1981</td>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.137835</td>\n",
       "      <td>0.137835</td>\n",
       "      <td>0.107256</td>\n",
       "      <td>55686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/1981</td>\n",
       "      <td>0.135603</td>\n",
       "      <td>0.135603</td>\n",
       "      <td>0.135045</td>\n",
       "      <td>0.135045</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>39827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>23/01/2023</td>\n",
       "      <td>138.119995</td>\n",
       "      <td>143.320007</td>\n",
       "      <td>137.899994</td>\n",
       "      <td>141.110001</td>\n",
       "      <td>141.110001</td>\n",
       "      <td>81760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>24/01/2023</td>\n",
       "      <td>140.309998</td>\n",
       "      <td>143.160004</td>\n",
       "      <td>140.300003</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>66435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td>25/01/2023</td>\n",
       "      <td>140.889999</td>\n",
       "      <td>142.429993</td>\n",
       "      <td>138.809998</td>\n",
       "      <td>141.860001</td>\n",
       "      <td>141.860001</td>\n",
       "      <td>65799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10606</th>\n",
       "      <td>26/01/2023</td>\n",
       "      <td>143.169998</td>\n",
       "      <td>144.250000</td>\n",
       "      <td>141.899994</td>\n",
       "      <td>143.960007</td>\n",
       "      <td>143.960007</td>\n",
       "      <td>54105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>27/01/2023</td>\n",
       "      <td>143.160004</td>\n",
       "      <td>147.229996</td>\n",
       "      <td>143.080002</td>\n",
       "      <td>145.929993</td>\n",
       "      <td>145.929993</td>\n",
       "      <td>70492800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Adj Close  \\\n",
       "0      02/01/1981    0.154018    0.155134    0.154018    0.154018    0.119849   \n",
       "1      05/01/1981    0.151228    0.151228    0.150670    0.150670    0.117244   \n",
       "2      06/01/1981    0.144531    0.144531    0.143973    0.143973    0.112032   \n",
       "3      07/01/1981    0.138393    0.138393    0.137835    0.137835    0.107256   \n",
       "4      08/01/1981    0.135603    0.135603    0.135045    0.135045    0.105085   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "10603  23/01/2023  138.119995  143.320007  137.899994  141.110001  141.110001   \n",
       "10604  24/01/2023  140.309998  143.160004  140.300003  142.529999  142.529999   \n",
       "10605  25/01/2023  140.889999  142.429993  138.809998  141.860001  141.860001   \n",
       "10606  26/01/2023  143.169998  144.250000  141.899994  143.960007  143.960007   \n",
       "10607  27/01/2023  143.160004  147.229996  143.080002  145.929993  145.929993   \n",
       "\n",
       "         Volume  \n",
       "0      21660800  \n",
       "1      35728000  \n",
       "2      45158400  \n",
       "3      55686400  \n",
       "4      39827200  \n",
       "...         ...  \n",
       "10603  81760300  \n",
       "10604  66435100  \n",
       "10605  65799300  \n",
       "10606  54105100  \n",
       "10607  70492800  \n",
       "\n",
       "[10608 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../data/quotes/apple_quotes.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to include only dates from 2020 onwards\n",
    "data = data[data['Date'] >= '2020-01-01']\n",
    "# Keep only 'Close' and 'Date' columns\n",
    "data = data[['Date', 'Close']]\n",
    "\n",
    "# Strip any whitespace from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Convert 'Close' column to float\n",
    "data['Close'] = data['Close'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Convert 'Date' column to datetime and sort by date\n",
    "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True)\n",
    "data = data.sort_values(by='Date')\n",
    "\n",
    "# Calculate log returns\n",
    "delta = 1\n",
    "data['Log_Return'] = np.log(data['Close'] / data['Close'].shift(delta))\n",
    "\n",
    "# Classification function h(x)\n",
    "def classify_return(x, gamma):\n",
    "    if x > gamma:\n",
    "        return 1  # Positive return\n",
    "    elif x < -gamma:\n",
    "        return -1  # Negative return\n",
    "    else:\n",
    "        return 0  # Stable return\n",
    "\n",
    "# Define the threshold for labeling TO OPTIMIZE LATER\n",
    "gamma = 0.01\n",
    "data['Return_Label'] = data['Log_Return'].apply(lambda x: classify_return(x, gamma))\n",
    "\n",
    "# Save the processed dataset\n",
    "data.to_csv(\"../data/processed/processed_apple_historical_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our quotes dataset includes the log return and looks like this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Log_Return</th>\n",
       "      <th>Return_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9835</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9836</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>75.797501</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>141.110001</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>141.860001</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10606</th>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>143.960007</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>145.929993</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Close  Log_Return  Return_Label\n",
       "9834  2020-01-02   75.087502         NaN             0\n",
       "9835  2020-01-03   74.357498   -0.009770             0\n",
       "9836  2020-01-06   74.949997    0.007937             0\n",
       "9837  2020-01-07   74.597504   -0.004714             0\n",
       "9838  2020-01-08   75.797501    0.015958             1\n",
       "...          ...         ...         ...           ...\n",
       "10603 2023-01-23  141.110001    0.023229             1\n",
       "10604 2023-01-24  142.529999    0.010013             1\n",
       "10605 2023-01-25  141.860001   -0.004712             0\n",
       "10606 2023-01-26  143.960007    0.014695             1\n",
       "10607 2023-01-27  145.929993    0.013591             1\n",
       "\n",
       "[774 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Linking it to the news data\n",
    "Now that we have a clean dataset to work on, let's merge our sentiment dataset with our returns dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_Symbol</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>9099</td>\n",
       "      <td>2020-03-10 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Peloton Shares Tick To Session Low As Hearing Report Apple Working On 'Guided Workout' Fitness App</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>9105</td>\n",
       "      <td>2020-03-10 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>UBS Maintains Buy on Apple, Lowers Price Target to $335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>9115</td>\n",
       "      <td>2020-05-31 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple CEO Writes To Employees About George Floyd Death, Urges For 'Better, More Just World For Everyone'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>9135</td>\n",
       "      <td>2020-05-28 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tredje AP-fonden Buys Microsoft Corp, Amazon.com Inc, Apple Inc, Sells iShares U.S. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>9136</td>\n",
       "      <td>2020-05-28 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>The Zacks Analyst Blog Highlights: Apple, Exxon Mobil, Cisco System and Chevron</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 Date Stock_Symbol  \\\n",
       "2779        9099  2020-03-10 00:00:00         AAPL   \n",
       "2780        9105  2020-03-10 00:00:00         AAPL   \n",
       "2781        9115  2020-05-31 00:00:00         AAPL   \n",
       "2782        9135  2020-05-28 00:00:00         AAPL   \n",
       "2783        9136  2020-05-28 00:00:00         AAPL   \n",
       "\n",
       "                                                                                                 Article_title  \\\n",
       "2779        Peloton Shares Tick To Session Low As Hearing Report Apple Working On 'Guided Workout' Fitness App   \n",
       "2780                                                   UBS Maintains Buy on Apple, Lowers Price Target to $335   \n",
       "2781  Apple CEO Writes To Employees About George Floyd Death, Urges For 'Better, More Just World For Everyone'   \n",
       "2782                   Tredje AP-fonden Buys Microsoft Corp, Amazon.com Inc, Apple Inc, Sells iShares U.S. ...   \n",
       "2783                           The Zacks Analyst Blog Highlights: Apple, Exxon Mobil, Cisco System and Chevron   \n",
       "\n",
       "      Sentiment  \n",
       "2779         -1  \n",
       "2780          1  \n",
       "2781          0  \n",
       "2782          0  \n",
       "2783          0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_data = pd.read_csv('../data/processed/processed_apple_historical_data.csv')\n",
    "sentiment_data = pd.read_csv('../data/processed/processed_news_data_with_sent.csv')\n",
    "sentiment_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Log_Return</th>\n",
       "      <th>Return_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>141.110001</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>141.860001</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>143.960007</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>145.929993</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close  Log_Return  Return_Label\n",
       "769  2023-01-23  141.110001    0.023229             1\n",
       "770  2023-01-24  142.529999    0.010013             1\n",
       "771  2023-01-25  141.860001   -0.004712             0\n",
       "772  2023-01-26  143.960007    0.014695             1\n",
       "773  2023-01-27  145.929993    0.013591             1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I proceed as follos :\n",
    "\n",
    "-News published after 4 PM is assigned to the next trading day using lambda, \n",
    "\n",
    "-Sentiment data is aggregated by trading day using the mean,\n",
    "\n",
    "-left join with returns_data to retain only rows with both sentiment and return data\n",
    "\n",
    "-Rows without corresponding sentiment data are dropped using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Process and check sentiment data and news published after 4PM are assigned to next trading day\n",
    "sentiment_data['Date'] = pd.to_datetime(sentiment_data['Date'])\n",
    "sentiment_data['Trading_Date'] = sentiment_data['Date'].apply(\n",
    "    lambda x: (x + pd.Timedelta(days=1)).date() if x.hour >= 16 else x.date()\n",
    ")\n",
    "\n",
    "# 2. Process and check returns data\n",
    "returns_data['Date'] = pd.to_datetime(returns_data['Date']).dt.date\n",
    "\n",
    "# 3. Create daily sentiment and check its dates\n",
    "daily_sentiment = sentiment_data.groupby('Trading_Date')['Sentiment'].mean().reset_index()\n",
    "\n",
    "# 4. Merge with printed diagnostics\n",
    "merged_data = pd.merge(\n",
    "    returns_data,\n",
    "    daily_sentiment,\n",
    "    left_on='Date',\n",
    "    right_on='Trading_Date',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 6. Check for any overlapping dates\n",
    "returns_dates = set(returns_data['Date'])\n",
    "sentiment_dates = set(daily_sentiment['Trading_Date'])\n",
    "overlapping_dates = returns_dates.intersection(sentiment_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Log_Return</th>\n",
       "      <th>Return_Label</th>\n",
       "      <th>Trading_Date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>71.334999</td>\n",
       "      <td>0.069546</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>68.857498</td>\n",
       "      <td>-0.035348</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>62.057499</td>\n",
       "      <td>-0.103978</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>69.492500</td>\n",
       "      <td>0.113157</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>60.552502</td>\n",
       "      <td>-0.137708</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Close  Log_Return  Return_Label Trading_Date  Sentiment\n",
       "0  2020-03-10  71.334999    0.069546             1   2020-03-10   0.000000\n",
       "1  2020-03-11  68.857498   -0.035348            -1   2020-03-11   0.142857\n",
       "2  2020-03-12  62.057499   -0.103978            -1   2020-03-12   0.000000\n",
       "3  2020-03-13  69.492500    0.113157             1   2020-03-13   0.375000\n",
       "4  2020-03-16  60.552502   -0.137708            -1   2020-03-16  -0.500000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
