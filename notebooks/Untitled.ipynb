{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2e230f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3052838167.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install transformers torch pandas\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers torch time pandas\n",
    "#pip install transformers torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374232a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "If you lack access to hardware with a GPU, consider using cloud platforms (e.g., Google Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396a403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/miniconda3/lib/python3.9/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118df230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.9/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (0.20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd5288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e5b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912e99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(WE HAVE TO REPLACE WITH REAL DAATA)\n",
    "texts = [\"The market is experiencing high volatility.\"] * 1000  # 1000 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea258a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 1000 requests: 32.66 seconds\n",
      "Average time per request: 0.0327 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmarking testing for the professor!\n",
    "start_time = time.time()\n",
    "results = []\n",
    "\n",
    "for text in texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        sentiment = torch.argmax(outputs.logits).item()  \n",
    "        results.append(sentiment)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate statistics\n",
    "total_time = end_time - start_time\n",
    "average_time = total_time / len(texts)\n",
    "\n",
    "# Display results\n",
    "print(f\"Total time for 1000 requests: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per request: {average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d702dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.85 seconds\n",
      "Average time per request: 0.0028 seconds\n"
     ]
    }
   ],
   "source": [
    "#same but use batch to fine tune \n",
    "batch_size = 32\n",
    "texts = [\"The market is volatile.\"] * 1000  \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_inputs)\n",
    "        sentiments = torch.argmax(outputs.logits, dim=1) \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "average_time = total_time / len(texts)\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per request: {average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a78f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 1000 requests: 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "#if we are allowed to use vader sentiment as we did for ML in Finance\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "for text in texts:\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    results.append(sentiment)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time for 1000 requests: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9dc85",
   "metadata": {},
   "source": [
    "# Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828475b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31225920",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34b45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2fb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_financial_data(ticker, start_date, end_date, interval=\"1m\"):\n",
    "    \"\"\"\n",
    "    Fetch historical financial data using Yahoo Finance API.\n",
    "    \"\"\"\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "    data.reset_index(inplace=True)\n",
    "    data.rename(columns={\"Datetime\": \"timestamp\"}, inplace=True)  # For consistency\n",
    "    # Ensure the financial data timestamps are in UTC\n",
    "    data[\"timestamp\"] = data[\"timestamp\"].dt.tz_convert(None)\n",
    "    print(\"Financial Data Sample:\")\n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf671631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic_sentiment_data(start_date, end_date, interval=\"1min\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic sentiment data with timestamps matching the financial data.\n",
    "    \"\"\"\n",
    "    timestamps = pd.date_range(start=start_date, end=end_date, freq=interval, tz=None)\n",
    "    sentiments = [random.choice([\"positive\", \"neutral\", \"negative\"]) for _ in range(len(timestamps))]\n",
    "    scores = [random.uniform(-1, 1) for _ in range(len(timestamps))]  # Sentiment intensity\n",
    "    sentiment_data = pd.DataFrame({\n",
    "        \"timestamp\": timestamps,\n",
    "        \"sentiment\": sentiments,\n",
    "        \"score\": scores\n",
    "    })\n",
    "    print(\"\\nSynthetic Sentiment Data Sample:\")\n",
    "    print(sentiment_data.head())\n",
    "    return sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c3ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(financial_data, sentiment_data):\n",
    "    \"\"\"\n",
    "    Combine financial data with sentiment data based on timestamps.\n",
    "    \"\"\"\n",
    "    financial_data[\"timestamp\"] = pd.to_datetime(financial_data[\"timestamp\"])\n",
    "    sentiment_data[\"timestamp\"] = pd.to_datetime(sentiment_data[\"timestamp\"])\n",
    "    \n",
    "    combined_data = pd.merge_asof(\n",
    "        sentiment_data.sort_values(by=\"timestamp\"), \n",
    "        financial_data.sort_values(by=\"timestamp\"), \n",
    "        on=\"timestamp\", \n",
    "        direction=\"backward\"\n",
    "    )\n",
    "    print(\"\\nCombined Data Sample:\")\n",
    "    print(combined_data.head())\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df4b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Financial Data Sample:\n",
      "            timestamp        Open        High         Low       Close  \\\n",
      "0 2024-12-02 14:30:00  237.270004  238.770004  237.160004  238.700897   \n",
      "1 2024-12-02 14:31:00  238.690002  239.059906  238.399994  239.000000   \n",
      "2 2024-12-02 14:32:00  238.960007  239.350006  238.910004  238.934601   \n",
      "3 2024-12-02 14:33:00  238.929993  239.199997  238.729996  239.110001   \n",
      "4 2024-12-02 14:34:00  239.080093  239.350006  238.929993  239.296295   \n",
      "\n",
      "    Adj Close   Volume  \n",
      "0  238.700897  2562715  \n",
      "1  239.000000   418941  \n",
      "2  238.934601   213308  \n",
      "3  239.110001   192847  \n",
      "4  239.296295   200970  \n",
      "\n",
      "Synthetic Sentiment Data Sample:\n",
      "            timestamp sentiment     score\n",
      "0 2024-12-01 00:00:00  negative  0.340362\n",
      "1 2024-12-01 00:01:00   neutral  0.248812\n",
      "2 2024-12-01 00:02:00   neutral  0.568798\n",
      "3 2024-12-01 00:03:00  negative -0.079361\n",
      "4 2024-12-01 00:04:00  negative -0.920842\n",
      "\n",
      "Combined Data Sample:\n",
      "            timestamp sentiment     score  Open  High  Low  Close  Adj Close  \\\n",
      "0 2024-12-01 00:00:00  negative  0.340362   NaN   NaN  NaN    NaN        NaN   \n",
      "1 2024-12-01 00:01:00   neutral  0.248812   NaN   NaN  NaN    NaN        NaN   \n",
      "2 2024-12-01 00:02:00   neutral  0.568798   NaN   NaN  NaN    NaN        NaN   \n",
      "3 2024-12-01 00:03:00  negative -0.079361   NaN   NaN  NaN    NaN        NaN   \n",
      "4 2024-12-01 00:04:00  negative -0.920842   NaN   NaN  NaN    NaN        NaN   \n",
      "\n",
      "   Volume  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "Combined data saved to 'combined_financial_sentiment_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    TICKER = \"AAPL\"  #^\n",
    "    START_DATE = (datetime.now() - timedelta(days=5)).strftime(\"%Y-%m-%d\")\n",
    "    END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    INTERVAL = \"1m\" \n",
    "    financial_data = fetch_financial_data(TICKER, START_DATE, END_DATE, INTERVAL)\n",
    "    sentiment_data = generate_synthetic_sentiment_data(START_DATE, END_DATE, interval=\"1min\")\n",
    "    combined_data = combine_data(financial_data, sentiment_data)\n",
    "    combined_data.to_csv(\"combined_financial_sentiment_data.csv\", index=False)\n",
    "    print(\"\\nCombined data saved to 'combined_financial_sentiment_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb82fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
